{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jXtmzJT48jyj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/train.csv')"
      ],
      "metadata": {
        "id": "LpxI4UQx9iNh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "2Ndao9E09ufF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.head())\n",
        "print(train_data.tail())\n",
        "\n",
        "print(test_data.head())\n",
        "print(test_data.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7Cjh8r091SJ",
        "outputId": "bc9913fa-01c1-4fe0-afd7-72f408efb4e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "     PassengerId  Survived  Pclass                                      Name  \\\n",
            "886          887         0       2                     Montvila, Rev. Juozas   \n",
            "887          888         1       1              Graham, Miss. Margaret Edith   \n",
            "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
            "889          890         1       1                     Behr, Mr. Karl Howell   \n",
            "890          891         0       3                       Dooley, Mr. Patrick   \n",
            "\n",
            "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
            "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
            "887  female  19.0      0      0      112053  30.00   B42        S  \n",
            "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
            "889    male  26.0      0      0      111369  30.00  C148        C  \n",
            "890    male  32.0      0      0      370376   7.75   NaN        Q  \n",
            "   PassengerId  Pclass                                          Name     Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    male   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
            "3          895       3                              Wirz, Mr. Albert    male   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
            "\n",
            "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
            "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
            "1  47.0      1      0   363272   7.0000   NaN        S  \n",
            "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
            "3  27.0      0      0   315154   8.6625   NaN        S  \n",
            "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
            "     PassengerId  Pclass                          Name     Sex   Age  SibSp  \\\n",
            "413         1305       3            Spector, Mr. Woolf    male   NaN      0   \n",
            "414         1306       1  Oliva y Ocana, Dona. Fermina  female  39.0      0   \n",
            "415         1307       3  Saether, Mr. Simon Sivertsen    male  38.5      0   \n",
            "416         1308       3           Ware, Mr. Frederick    male   NaN      0   \n",
            "417         1309       3      Peter, Master. Michael J    male   NaN      1   \n",
            "\n",
            "     Parch              Ticket      Fare Cabin Embarked  \n",
            "413      0           A.5. 3236    8.0500   NaN        S  \n",
            "414      0            PC 17758  108.9000  C105        C  \n",
            "415      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
            "416      0              359309    8.0500   NaN        S  \n",
            "417      1                2668   22.3583   NaN        C  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Function to extract title and map it to a number\n",
        "def extract_and_map_title(df):\n",
        "    # Extract titles from names\n",
        "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "    # Print unique titles to see what we're working with\n",
        "    print(\"Unique titles:\", df['Title'].unique())\n",
        "\n",
        "    # Map titles to numbers\n",
        "    title_mapping = {\n",
        "        \"Mr\": 1,\n",
        "        \"Miss\": 2,\n",
        "        \"Mrs\": 3,\n",
        "        \"Master\": 4,\n",
        "        \"Dr\": 5,\n",
        "        \"Rev\": 6,\n",
        "        \"Col\": 7,\n",
        "        \"Major\": 7,\n",
        "        \"Mlle\": 8,\n",
        "        \"Countess\": 9,\n",
        "        \"Ms\": 10,\n",
        "        \"Lady\": 11,\n",
        "        \"Jonkheer\": 12,\n",
        "        \"Don\": 13,\n",
        "        \"Dona\": 14,\n",
        "        \"Mme\": 15,\n",
        "        \"Capt\": 16,\n",
        "        \"Sir\": 17\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the Title column\n",
        "    df['Title'] = df['Title'].map(title_mapping)\n",
        "\n",
        "    # Fill any missing values with 0 (in case there are any titles we didn't account for)\n",
        "    df['Title'] = df['Title'].fillna(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the title extraction and mapping to both datasets\n",
        "train_df = extract_and_map_title(train_df)\n",
        "test_df = extract_and_map_title(test_df)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_df.to_csv('train_updated.csv', index=False)\n",
        "test_df.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "# Print the first few rows to verify the changes\n",
        "print(\"Updated Training Data:\")\n",
        "print(train_df.head())\n",
        "print(\"Updated Testing Data:\")\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWm977u2-Jdg",
        "outputId": "bf2ba391-abd5-4e5a-f17e-7467def3b1f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique titles: ['Mr' 'Mrs' 'Miss' 'Master' 'Don' 'Rev' 'Dr' 'Mme' 'Ms' 'Major' 'Lady'\n",
            " 'Sir' 'Mlle' 'Col' 'Capt' 'Countess' 'Jonkheer']\n",
            "Unique titles: ['Mr' 'Mrs' 'Miss' 'Master' 'Ms' 'Col' 'Rev' 'Dr' 'Dona']\n",
            "Updated Training Data:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  Title  \n",
            "0      0         A/5 21171   7.2500   NaN        S      1  \n",
            "1      0          PC 17599  71.2833   C85        C      3  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S      2  \n",
            "3      0            113803  53.1000  C123        S      3  \n",
            "4      0            373450   8.0500   NaN        S      1  \n",
            "Updated Testing Data:\n",
            "   PassengerId  Pclass                                          Name     Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    male   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
            "3          895       3                              Wirz, Mr. Albert    male   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
            "\n",
            "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Title  \n",
            "0  34.5      0      0   330911   7.8292   NaN        Q      1  \n",
            "1  47.0      1      0   363272   7.0000   NaN        S      3  \n",
            "2  62.0      0      0   240276   9.6875   NaN        Q      1  \n",
            "3  27.0      0      0   315154   8.6625   NaN        S      1  \n",
            "4  22.0      1      1  3101298  12.2875   NaN        S      3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert Sex to numeric\n",
        "def convert_sex_to_numeric(df):\n",
        "    df['Sex'] = df['Sex'].map({'female': 0, 'male': 1})\n",
        "    return df\n",
        "\n",
        "# Load and process train dataset\n",
        "train_df = pd.read_csv('train_updated.csv')\n",
        "train_df = convert_sex_to_numeric(train_df)\n",
        "\n",
        "# Load and process test dataset\n",
        "test_df = pd.read_csv('test_updated.csv')\n",
        "test_df = convert_sex_to_numeric(test_df)\n",
        "\n",
        "# Print the first few rows to verify the change\n",
        "print(\"Train dataset (first 5 rows):\")\n",
        "print(train_df[['PassengerId', 'Sex']].head())\n",
        "\n",
        "print(\"\\nTest dataset (first 5 rows):\")\n",
        "print(test_df[['PassengerId', 'Sex']].head())\n",
        "\n",
        "# Save the updated datasets\n",
        "train_df.to_csv('train_updated.csv', index=False)\n",
        "test_df.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"\\nDatasets updated and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfgyea1q_1w3",
        "outputId": "ab6c7669-dcc5-44e9-ee3c-56f75b231ab5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset (first 5 rows):\n",
            "   PassengerId  Sex\n",
            "0            1    1\n",
            "1            2    0\n",
            "2            3    0\n",
            "3            4    0\n",
            "4            5    1\n",
            "\n",
            "Test dataset (first 5 rows):\n",
            "   PassengerId  Sex\n",
            "0          892    1\n",
            "1          893    0\n",
            "2          894    1\n",
            "3          895    1\n",
            "4          896    0\n",
            "\n",
            "Datasets updated and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the updated datasets\n",
        "train_df = pd.read_csv('train_updated.csv')\n",
        "test_df = pd.read_csv('test_updated.csv')\n",
        "\n",
        "def process_data(df):\n",
        "    # Merge SibSp and Parch into FamilySize\n",
        "    df['FamilySize'] = df['SibSp'] + df['Parch']\n",
        "\n",
        "    # Convert 'Sex' to numeric if it's not already\n",
        "    if df['Sex'].dtype == 'object':\n",
        "        df['Sex'] = df['Sex'].map({'female': 0, 'male': 1})\n",
        "\n",
        "    # Convert 'Ticket' to numeric\n",
        "    df['Ticket'] = pd.factorize(df['Ticket'])[0]\n",
        "\n",
        "    return df\n",
        "\n",
        "# Process both datasets\n",
        "train_df = process_data(train_df)\n",
        "test_df = process_data(test_df)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_df.to_csv('train_updated.csv', index=False)\n",
        "test_df.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"Updated datasets have been saved.\")\n",
        "\n",
        "# Display the first few rows and data info of the training dataset\n",
        "print(\"\\nFirst few rows of the updated training dataset:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nDataset Info:\")\n",
        "print(train_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyEJtaoQAVoy",
        "outputId": "c3ac1bc9-a645-459c-dcff-d29fcf6cba98"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated datasets have been saved.\n",
            "\n",
            "First few rows of the updated training dataset:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex   Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
            "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
            "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
            "\n",
            "   Ticket     Fare Cabin Embarked  Title  FamilySize  \n",
            "0       0   7.2500   NaN        S      1           1  \n",
            "1       1  71.2833   C85        C      3           1  \n",
            "2       2   7.9250   NaN        S      2           0  \n",
            "3       3  53.1000  C123        S      3           1  \n",
            "4       4   8.0500   NaN        S      1           0  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 14 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    int64  \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    int64  \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            " 12  Title        891 non-null    int64  \n",
            " 13  FamilySize   891 non-null    int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 97.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "train_df = pd.read_csv('train_updated.csv')\n",
        "test_df = pd.read_csv('test_updated.csv')\n",
        "\n",
        "# Drop 'Cabin' and 'Ticket' columns\n",
        "columns_to_drop = ['Cabin', 'Ticket']\n",
        "train_df = train_df.drop(columns=columns_to_drop)\n",
        "test_df = test_df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_df.to_csv('train_updated.csv', index=False)\n",
        "test_df.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"Columns dropped and datasets updated.\")\n",
        "\n",
        "# Display information about the updated datasets\n",
        "print(\"\\nUpdated training dataset info:\")\n",
        "print(train_df.info())\n",
        "\n",
        "print(\"\\nUpdated testing dataset info:\")\n",
        "print(test_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itwiK1k2A18c",
        "outputId": "de88f55c-f60c-4efb-b44a-ff02c366a8e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns dropped and datasets updated.\n",
            "\n",
            "Updated training dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    int64  \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Fare         891 non-null    float64\n",
            " 9   Embarked     889 non-null    object \n",
            " 10  Title        891 non-null    int64  \n",
            " 11  FamilySize   891 non-null    int64  \n",
            "dtypes: float64(2), int64(8), object(2)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "\n",
            "Updated testing dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    int64  \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Fare         417 non-null    float64\n",
            " 8   Embarked     418 non-null    object \n",
            " 9   Title        418 non-null    int64  \n",
            " 10  FamilySize   418 non-null    int64  \n",
            "dtypes: float64(2), int64(7), object(2)\n",
            "memory usage: 36.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the updated datasets\n",
        "train_df = pd.read_csv('train_updated.csv')\n",
        "test_df = pd.read_csv('test_updated.csv')\n",
        "\n",
        "# Function to process the dataset\n",
        "def process_age(df, dataset_name):\n",
        "    # Print the number of null values in the Age column\n",
        "    null_age_count = df['Age'].isnull().sum()\n",
        "    print(f\"Number of null values in Age column ({dataset_name}): {null_age_count}\")\n",
        "\n",
        "    # Fill null values in Age column with 29\n",
        "    df['Age'].fillna(29, inplace=True)\n",
        "\n",
        "    # Verify that there are no more null values in Age column\n",
        "    null_age_count_after = df['Age'].isnull().sum()\n",
        "    print(f\"Number of null values in Age column after filling ({dataset_name}): {null_age_count_after}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Process train dataset\n",
        "train_df = process_age(train_df, \"train\")\n",
        "\n",
        "# Process test dataset\n",
        "test_df = process_age(test_df, \"test\")\n",
        "\n",
        "# Save the updated datasets\n",
        "train_df.to_csv('train_updated.csv', index=False)\n",
        "test_df.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"Updated datasets have been saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQCG7jqqBRy-",
        "outputId": "f4da52e6-25b9-4612-b9dd-957f4ec44027"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of null values in Age column (train): 177\n",
            "Number of null values in Age column after filling (train): 0\n",
            "Number of null values in Age column (test): 86\n",
            "Number of null values in Age column after filling (test): 0\n",
            "Updated datasets have been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_age(age):\n",
        "    if pd.isna(age):\n",
        "        return 0  # For missing values\n",
        "    elif 0 <= age <= 25:\n",
        "        return 1\n",
        "    elif 26 <= age <= 50:\n",
        "        return 2\n",
        "    elif 51 <= age <= 75:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n",
        "\n",
        "# Load the updated datasets\n",
        "train_df = pd.read_csv('train_updated.csv')\n",
        "test_df = pd.read_csv('test_updated.csv')\n",
        "\n",
        "# Apply age categorization\n",
        "train_df['AgeCategory'] = train_df['Age'].apply(categorize_age)\n",
        "test_df['AgeCategory'] = test_df['Age'].apply(categorize_age)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_df.to_csv('train_updated.csv', index=False)\n",
        "test_df.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"Age categorization completed and datasets updated.\")\n",
        "\n",
        "# Display the first few rows of each dataset to verify the changes\n",
        "print(\"\\nFirst few rows of the updated training dataset:\")\n",
        "print(train_df[['PassengerId', 'Age', 'AgeCategory']].head())\n",
        "\n",
        "print(\"\\nFirst few rows of the updated testing dataset:\")\n",
        "print(test_df[['PassengerId', 'Age', 'AgeCategory']].head())\n",
        "\n",
        "# Display value counts of AgeCategory\n",
        "print(\"\\nAge Category distribution in training dataset:\")\n",
        "print(train_df['AgeCategory'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nAge Category distribution in testing dataset:\")\n",
        "print(test_df['AgeCategory'].value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJweObaECVMu",
        "outputId": "b3d2f918-dc7a-4ef4-faa6-693156bf56bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age categorization completed and datasets updated.\n",
            "\n",
            "First few rows of the updated training dataset:\n",
            "   PassengerId   Age  AgeCategory\n",
            "0            1  22.0            1\n",
            "1            2  38.0            2\n",
            "2            3  26.0            2\n",
            "3            4  35.0            2\n",
            "4            5  35.0            2\n",
            "\n",
            "First few rows of the updated testing dataset:\n",
            "   PassengerId   Age  AgeCategory\n",
            "0          892  34.5            2\n",
            "1          893  47.0            2\n",
            "2          894  62.0            3\n",
            "3          895  27.0            2\n",
            "4          896  22.0            1\n",
            "\n",
            "Age Category distribution in training dataset:\n",
            "AgeCategory\n",
            "1    301\n",
            "2    526\n",
            "3     63\n",
            "4      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Age Category distribution in testing dataset:\n",
            "AgeCategory\n",
            "1    142\n",
            "2    245\n",
            "3     30\n",
            "4      1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the updated datasets\n",
        "train_df = pd.read_csv('train_updated.csv')\n",
        "test_df = pd.read_csv('test_updated.csv')\n",
        "\n",
        "# Drop the 'Fare' column from both datasets\n",
        "train_df = train_df.drop('Fare', axis=1)\n",
        "test_df = test_df.drop('Fare', axis=1)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_df.to_csv('train_updated.csv', index=False)\n",
        "test_df.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"'Fare' column dropped and datasets updated.\")\n",
        "\n",
        "# Display the first few rows of each dataset to verify the changes\n",
        "print(\"\\nFirst few rows of the updated training dataset:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nFirst few rows of the updated testing dataset:\")\n",
        "print(test_df.head())\n",
        "\n",
        "# Display column names to confirm 'Fare' is removed\n",
        "print(\"\\nColumns in the training dataset:\")\n",
        "print(train_df.columns.tolist())\n",
        "\n",
        "print(\"\\nColumns in the testing dataset:\")\n",
        "print(test_df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCSuRl0TDE4_",
        "outputId": "db6def8a-28b2-454e-e492-a9d6f0a4ad2b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Fare' column dropped and datasets updated.\n",
            "\n",
            "First few rows of the updated training dataset:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex   Age  SibSp  Parch  \\\n",
            "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
            "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
            "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
            "\n",
            "  Embarked  Title  FamilySize  AgeCategory  \n",
            "0        S      1           1            1  \n",
            "1        C      3           1            2  \n",
            "2        S      2           0            2  \n",
            "3        S      3           1            2  \n",
            "4        S      1           0            2  \n",
            "\n",
            "First few rows of the updated testing dataset:\n",
            "   PassengerId  Pclass                                          Name  Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    1   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
            "3          895       3                              Wirz, Mr. Albert    1   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
            "\n",
            "    Age  SibSp  Parch Embarked  Title  FamilySize  AgeCategory  \n",
            "0  34.5      0      0        Q      1           0            2  \n",
            "1  47.0      1      0        S      3           1            2  \n",
            "2  62.0      0      0        Q      1           0            3  \n",
            "3  27.0      0      0        S      1           0            2  \n",
            "4  22.0      1      1        S      3           2            1  \n",
            "\n",
            "Columns in the training dataset:\n",
            "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Title', 'FamilySize', 'AgeCategory']\n",
            "\n",
            "Columns in the testing dataset:\n",
            "['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked', 'Title', 'FamilySize', 'AgeCategory']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the updated datasets\n",
        "train_df = pd.read_csv('train_updated.csv')\n",
        "test_df = pd.read_csv('test_updated.csv')\n",
        "\n",
        "# Columns to drop\n",
        "columns_to_drop = ['SibSp', 'Parch', 'TitleNum', 'Age']\n",
        "\n",
        "# Drop the specified columns from both datasets\n",
        "train_df = train_df.drop(columns=columns_to_drop, errors='ignore')\n",
        "test_df = test_df.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Save the updated datasets\n",
        "train_df.to_csv('train_updated.csv', index=False)\n",
        "test_df.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"Specified columns dropped and datasets updated.\")\n",
        "\n",
        "# Display the first few rows of each dataset to verify the changes\n",
        "print(\"\\nFirst few rows of the updated training dataset:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nFirst few rows of the updated testing dataset:\")\n",
        "print(test_df.head())\n",
        "\n",
        "# Display column names to confirm dropped columns\n",
        "print(\"\\nColumns in the training dataset:\")\n",
        "print(train_df.columns.tolist())\n",
        "\n",
        "print(\"\\nColumns in the testing dataset:\")\n",
        "print(test_df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAoF75jcDRwh",
        "outputId": "7d275da2-3d7a-4040-e232-9e55f2681959"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specified columns dropped and datasets updated.\n",
            "\n",
            "First few rows of the updated training dataset:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name  Sex Embarked  Title  \\\n",
            "0                            Braund, Mr. Owen Harris    1        S      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0        C      3   \n",
            "2                             Heikkinen, Miss. Laina    0        S      2   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0        S      3   \n",
            "4                           Allen, Mr. William Henry    1        S      1   \n",
            "\n",
            "   FamilySize  AgeCategory  \n",
            "0           1            1  \n",
            "1           1            2  \n",
            "2           0            2  \n",
            "3           1            2  \n",
            "4           0            2  \n",
            "\n",
            "First few rows of the updated testing dataset:\n",
            "   PassengerId  Pclass                                          Name  Sex  \\\n",
            "0          892       3                              Kelly, Mr. James    1   \n",
            "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
            "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
            "3          895       3                              Wirz, Mr. Albert    1   \n",
            "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
            "\n",
            "  Embarked  Title  FamilySize  AgeCategory  \n",
            "0        Q      1           0            2  \n",
            "1        S      3           1            2  \n",
            "2        Q      1           0            3  \n",
            "3        S      1           0            2  \n",
            "4        S      3           2            1  \n",
            "\n",
            "Columns in the training dataset:\n",
            "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Embarked', 'Title', 'FamilySize', 'AgeCategory']\n",
            "\n",
            "Columns in the testing dataset:\n",
            "['PassengerId', 'Pclass', 'Name', 'Sex', 'Embarked', 'Title', 'FamilySize', 'AgeCategory']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('train_updated.csv')\n",
        "test_df = pd.read_csv('test_updated.csv')\n",
        "\n",
        "train_df = train_df.drop('Name', axis=1)\n",
        "test_df = test_df.drop('Name', axis=1)\n",
        "\n",
        "train_df.to_csv('train_updated.csv', index=False)\n",
        "test_df.to_csv('test_updated.csv', index=False)"
      ],
      "metadata": {
        "id": "jj3--RPWDvVD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the updated datasets\n",
        "train_df = pd.read_csv('train_updated.csv')\n",
        "test_df = pd.read_csv('test_updated.csv')\n",
        "\n",
        "def convert_embarked(df):\n",
        "    # Check the data type of the Embarked column\n",
        "    print(\"Embarked column data type:\", df['Embarked'].dtype)\n",
        "    print(\"Unique values in Embarked column:\", df['Embarked'].unique())\n",
        "\n",
        "    # Define the mapping\n",
        "    embarked_mapping = {'S': 1, 'Q': 2, 'C': 3}\n",
        "\n",
        "    # Convert to numeric if it's not already\n",
        "    if df['Embarked'].dtype == 'object':\n",
        "        df['Embarked'] = df['Embarked'].map(embarked_mapping)\n",
        "    else:\n",
        "        # If it's already numeric, round and clip the values\n",
        "        df['Embarked'] = df['Embarked'].round().clip(1, 3)\n",
        "\n",
        "    # Fill any NaN values with the most common value\n",
        "    most_common = df['Embarked'].mode()[0]\n",
        "    df['Embarked'] = df['Embarked'].fillna(most_common)\n",
        "\n",
        "    # Ensure all values are integers\n",
        "    df['Embarked'] = df['Embarked'].astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply the conversion to both datasets\n",
        "train_df = convert_embarked(train_df)\n",
        "test_df = convert_embarked(test_df)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_df.to_csv('train_updated.csv', index=False)\n",
        "test_df.to_csv('test_updated.csv', index=False)\n",
        "\n",
        "print(\"Embarked values converted and datasets updated.\")\n",
        "\n",
        "# Display the first few rows of each dataset to verify the changes\n",
        "print(\"\\nFirst few rows of the updated training dataset:\")\n",
        "print(train_df[['PassengerId', 'Embarked']].head())\n",
        "\n",
        "print(\"\\nFirst few rows of the updated testing dataset:\")\n",
        "print(test_df[['PassengerId', 'Embarked']].head())\n",
        "\n",
        "# Display value counts of Embarked\n",
        "print(\"\\nEmbarked value counts in training dataset:\")\n",
        "print(train_df['Embarked'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nEmbarked value counts in testing dataset:\")\n",
        "print(test_df['Embarked'].value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jooWDIFgJBLV",
        "outputId": "75507d95-61e1-433e-ebd0-5c1a8e388699"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embarked column data type: object\n",
            "Unique values in Embarked column: ['S' 'C' 'Q' nan]\n",
            "Embarked column data type: object\n",
            "Unique values in Embarked column: ['Q' 'S' 'C']\n",
            "Embarked values converted and datasets updated.\n",
            "\n",
            "First few rows of the updated training dataset:\n",
            "   PassengerId  Embarked\n",
            "0            1         1\n",
            "1            2         3\n",
            "2            3         1\n",
            "3            4         1\n",
            "4            5         1\n",
            "\n",
            "First few rows of the updated testing dataset:\n",
            "   PassengerId  Embarked\n",
            "0          892         2\n",
            "1          893         1\n",
            "2          894         2\n",
            "3          895         1\n",
            "4          896         1\n",
            "\n",
            "Embarked value counts in training dataset:\n",
            "Embarked\n",
            "1    646\n",
            "2     77\n",
            "3    168\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Embarked value counts in testing dataset:\n",
            "Embarked\n",
            "1    270\n",
            "2     46\n",
            "3    102\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Load the updated datasets\n",
        "train_data = pd.read_csv('train_updated.csv')\n",
        "test_data = pd.read_csv('test_updated.csv')\n",
        "\n",
        "# Separate features and target for training data\n",
        "X_train = train_data.drop('Survived', axis=1)\n",
        "Y_train = train_data['Survived']\n",
        "\n",
        "# Prepare test data\n",
        "X_test = test_data.copy()\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Support Vector Machines': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Perceptron': Perceptron(),\n",
        "    'Stochastic Gradient Descent': SGDClassifier(),\n",
        "    'Linear SVC': LinearSVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "# Train models and calculate accuracy\n",
        "accuracies = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, Y_train)\n",
        "    acc = round(model.score(X_train_scaled, Y_train) * 100, 2)\n",
        "    accuracies[name] = acc\n",
        "\n",
        "# Sort accuracies from largest to smallest\n",
        "sorted_accuracies = dict(sorted(accuracies.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "# Print sorted accuracies\n",
        "print(\"\\nModel Accuracies (sorted from largest to smallest):\")\n",
        "for model, accuracy in sorted_accuracies.items():\n",
        "    print(f\"{model}: {accuracy}%\")\n",
        "\n",
        "# Optional: Make predictions with the best model (assuming Random Forest is best)\n",
        "best_model = models['Random Forest']\n",
        "Y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'PassengerId': test_data['PassengerId'],\n",
        "    'Survived': Y_pred\n",
        "})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"\\nPredictions saved to 'submission.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6QN_DOrKqPH",
        "outputId": "14f48c08-517c-4a44-fa84-c7d6d2b26686"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracies (sorted from largest to smallest):\n",
            "Random Forest: 100.0%\n",
            "Decision Tree: 100.0%\n",
            "KNN: 85.19%\n",
            "Support Vector Machines: 83.95%\n",
            "Logistic Regression: 80.7%\n",
            "Stochastic Gradient Descent: 80.58%\n",
            "Perceptron: 79.69%\n",
            "Linear SVC: 79.69%\n",
            "Naive Bayes: 79.57%\n",
            "\n",
            "Predictions saved to 'submission.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}